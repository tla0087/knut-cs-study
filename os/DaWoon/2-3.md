# 컴퓨터 성능 향상 기술

<br>

```
현대 컴퓨터 구조의 가장 큰 문제는 CPU와 메모리, 주변장치의 작업속도가 다르다는 것이다.
메인보드 내 메모리와 주변장치는 시스템 버스의 영향을 받고, CPU 내 레지스터, ALU, 제어장치는 CPU 내부 버스의 영향을 받는다.

작업 속도가 높은 순으로 나열하면 CPU > 메모리 및 주변장치 > 하드디스크이고, 각 장치의 작업속도가 얼마나 시너지를 잘 내느냐에 따라서 성능 저하 혹은 성능 향상이 된다.

그렇다면, 어떻게 컴퓨터 성능을 향상 시킬 수 있을까?
```

<br>

## 버퍼
```
버퍼는 속도에 차이가 있는 두 장치 사이에서 그 차이를 완화하는 역할을 한다.
```
- 버퍼는 일정량의 데이터를 **모아 옮김**으로써 속도의 차이를 완화하는 장치다.
   + 버퍼 = 물건을 많이 담을 수 있는 바구니 or 가방
- HDD 속에는 메모리 버퍼가 존재
   + 예시) 1TB, 7500rpm, **32MB**
     * 위 예시의 사양 => 용량 1TB, 디스크의 회전 속도 7500rpm, **버퍼의 용량 32MB**
     * 만약, 같은 용량과 같은 회전 속도를 가진 HDD가 2개가 있다면, 버퍼의 용량에 따라 속도가 달라짐
- 버퍼는 하드웨어적으로만 사용되는 개념이 아니다.
  + 소프트웨어적으로 사용되는 대표적인 예 => 동영상 스트리밍
    * 네트워크에서 데이터가 들어오는 시간 < 플레이어가 재생되는 시간 => 영상끊김
    * 영상 끊김을 방지하기 위해 동영상 데이터의 일부분을 버퍼에 넣음

<br>

## 스풀
```
CPU와 입출력장치가 독립적으로 동작하도록 고안된 소프트웨어적인 버퍼
```
- 대표적인 예) 프린터에 사용되는 스풀러(Spooler)
   + 스풀러 : 인쇄할 내용을 순차적으로 출력하는 소프트웨어
   + 출력 명령을 내린 프로그램과 **독립적**으로 동작한다.
     * 상황) 한글 프로그램으로 작업 후, 프린팅을 해야되는 상황
     * 스풀러가 없으면 한글 프로그램이 인쇄 작업까지 담당하게 됨 => 인쇄가 끝날 때까지 한글 프로그램 사용 불가
     * 스풀러를 사용하면 인쇄할 내용을 HDD의 스풀러 공간에 저장하고, 한글은 다른 작업을 할 수 있음 (두가지 작업의 병행 => 독립)
   + 스풀러는 일종의 버퍼이지만, 버퍼와는 다르다.
     * 버퍼 => **어떤 프로그램이 사용하는 데이터든** 버퍼가 차면 데이터 이동 => 프로그램들이 공유한다.
     * 스풀러 => 한 인쇄물이 완료될 때까지 다른 이쇄물이 끼어들 수 없음 => 배타적

<br>

## 캐시
```
캐시는 CPU와 메모리간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 장소이다.
```
- 버퍼의 일종으로 CPU가 앞으로 사용할 것으로 예상되는 데이터를 미리 저장
    + 이 작업을 '미리 가져오기(prefetch)'라고 함
- 캐시는 CPU 내부에 있고, CPU 내부 버스의 속도로 작동한다.
- 캐시는 빠른 속도로 작동하는 CPU와 느린 속도로 작동하는 메모리 사이에서 두 장치의 속도 차이를 완화해준다.
- 캐시의 작동순서
  1. 캐시가 메모리의 내용 중 일부를 미리 가져오고, CPU는 메모리에 접근해야 할 때 캐시를 먼저 방문하여 원하는 데이터가 있는지 찾아본다.
  2. 캐시에서 원하는 데이터를 찾았다면 캐시 히트(Cache Hit)라고 하며, 해당 데이터를 바로 사용한다.
  3. 원하는 데이터가 존재하지 않으면 메모리로 가서 데이터를 찾아온다. (캐시 미스, Cache Miss) 
- 캐쉬 히트가 되는 비율 = 캐쉬 적중률(Cache hit ratio)
- 컴퓨터의 성능을 향상하려면 캐시 적중률이 높아야 함
- 캐시 적중률을 올리는 방법
  1. 캐시의 크기를 늘리는 방법 
     + 캐시의 크기가 커지면 더 많은 데이터를 미리 가져올 수 있기 때문에 적중률 ↑
     + 하지만 캐시는 비싸기 때문에 늘리는 건 한계가 있다.
  2. 자주 사용될 데이터를 가져오는 방법
     + 관련된 이론으로 지역성(Locality) 이론이 있다
        * 현재 위치에 가까운 데이터가 멀리 있는 데이터보다 사용될 확률이 더 높다는 이론
        * 예시) 프로그램의 10번 행이 실행되고 있다면, 다음에 11번 행이 실행될 확률이 101번 행이 실행될 확률보다 더 높다. 따라서, 미리 11~20번 행을 가져오면 된다.

<br>

## 즉시 쓰기와 지연 쓰기
```
캐시의 변경된 데이터를 메모리에 반영하는 데에는 즉시 쓰기와 지연 쓰기가 있다.
``` 
- 즉시 쓰기
  + 캐시에 있는 데이터가 변경되면 이를 즉시 메모리에 반영하는 방식이다.
  + 메모리와의 빈번한 데이터 전송 => 성능이 떨어진다는 단점이 있다.
  + 최신 값이 항상 유지되므로 데이터를 잃어버리지 않는다.
- 지연 쓰기
  + 즉시 반영하는게 아닌, 변경된 내용을 모아서 주기적으로 반영하는 방식
  + 카비 백(Copy Back)이라고도 불린다.
  + 데이터가 바로바로 최신화되지 않음 => 메모리와 캐시된 데이터 사이의 불일치가 발생 할 수 있다.
  + 메모리와의 데이터 전송 횟수가 줄어들어 시스템의 성능을 향상시킬 수 있다.

<br>

## L1 캐시와 L2 캐시
```
명령어 = 명령어 부분(어떤 작업을 할 것인가?) + 데이터 부분(작업 대상)

일반 캐시 : 명령어와 데이터의 구분없이 모든 자료를 가져오는 캐시
특수 캐시 : 명령어와 데이터를 구분하여 가져오는 캐시
```
- 캐시의 구조
```
명령어 레지스터         데이터 레지스터
      |                      |
  명령어 캐시             데이터 캐시      => L1
      |                      |
  ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ         
  |        캐           시            |   => L2
  ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
```
+ 명령어 캐시나 데이터 캐시는 CPU 레지스터에 직접 연결되기 때문에 L1(Level 1) 캐시라고 부른다.
+ 일반 캐시는 메모리와 연결되기 때문에 L2(Level 2)캐시라고 부른다.

<br>

## 저장장치의 계층 구조
```
저장장치의 계층 구조(Storage Hierarchy)는 속도가 빠르고 값이 비싼 저장장치를 CPU 가까운 쪽에 두고, 값이 싸고 용량이 큰 저장장치를 반대쪽에 배치하여 적당한 가격으로 빠른 속도와 큰 용량을 동시에 얻는 방법이다.
```
- 저장장치의 계층 구조에서는 CPU와 가까운 쪽에 레지스터나 캐시를 배치하여 CPU가 작업을 빨리 진행할 수 있게 한다.
- 메모리에서 작업한 내용을 HDD와 같이 저렴하고 용량이 큰 저장장치에 영구적으로 저장할 수 있게 한다.
- 하지만 저장장치의 계층 구조는 중복되는 데이터의 일관성을 유지하는 것이 문제이다. (지연 쓰기의 경우 문제가 된다는 뜻) 

<br>

# 인터럽트

## 인터럽트의 개념
```
초기 컴퓨터는 CPU가 직접 입출력장치에서 데이터를 가져오거나 내보냈는데, 이러한 방식을 폴링(Polling) 방식이라고 부른다. 이 방식은 CPU가 명령어 해석과 실행 외에도 모든 입출력까지 관여해야 하므로 작업 효율이 상당히 떨어졌다.

오늘날의 컴퓨터는 많은 주변장치가 있기 때문에 CPU가 모든 입출력에 관여하면 효율이 현저하게 떨어진다. 이러한 문제를 해결하기 위해 인터럽트(Interrupt) 방식이 생겨났다.
```
- 인터럽트 방식은 CPU의 작업과 저장장치의 데이터 이동을 **독립적으로 운영**함으로써 시스템의 효율을 높인다.

<br>

## 인터럽트 방식의 동작 과정
```
1. CPU가 입출력 관리자에게 입출력 명령을 보낸다.
2. 입출력 관리자는 명령받은 데이터를 메모리에 가져다놓거나 메모리에 있는 데이터를 저장장치로 옮긴다.
3. 데이터 전송이 완료되면 입출력 관리자는 완료 신호를 CPU에게 보낸다.
```
- **입출력 관리자가 CPU에 보내는 완료 신호를 인터럽트**라고 한다.
- 인터럽트 방식에서는 많은 주변장치 중 **어떤 것의 작업이 끝났는지를 CPU에 알려주기 위해 인터럽트 번호**를 사용한다.
  + 인터럽트 번호는 완료 신호를 보낼 때 장치의 이름 대신 사용하는 장치의 고유번호로서 운영체제마다 다르다.
- CPU는 입출력 관리자에게 여러 개의 입출력 작업을 **동시에** 시킬 수 있다.
- 여러 작업이 동시에 완료되고 그때마다 인터럽트를 여러 번 사용해야 하는데 이는 매우 비효율적
- 이러한 것을 막기 위해 **여러 개의 인터럽트를 하나의 배열로 만든 인터럽트 벡터를 사용한다.**
- 인터럽트는 입출력 요청 -> 데이터 전송 -> 인터럽트 발생 순으로 진행된다.
- 인터럽트 벡터의 예시
```
인터럽트 발생
       ↓
 1  2  3  4  5
[O  X  X  O  X]       => 인터럽트 벡터 생성
       ↓
인터럽트 벡터를 받은 CPU는 0번과 3번 작업을 동시에 처리
```
- 입출력이 완료되었음을 알리는 것 외에도 다양한 인터럽트가 있다.
- 컴퓨터 강제 종료, 진행중인 작업이 메모리 영역을 넘어서려거나 0으로 숫자를 나누면 인터럽트가 발생한다.

<br>

## 직접 메모리 접근
```
입출력이 필요할 때 CPU는 입출력 관리자에게 입출력 요청을 보내고 자신은 하던 일을 계속한다. 명령을 받은 입출력 관리자는 CPU가 요청한 데이터를 메모리에 가져다놓아야 하는데 이때 문제가 있다.

메모리는 CPU만 접근 권한을 가진 작업공간이라 입출력 관리자는 접근이 '불가'하다는 것이다.
```
- 입출력 관리자에게는 CPU의 허락없이 메모리에 접근할 수 있는 권한이 필요한데, 이러한 권한을 **직접 메모리 접근**이라 한다.
- 데이터 전송을 지시받은 입출력 관리자는 직접 메모리 접근 권한이 있어야 CPU의 관여없이 작업을 완료할 수 있다.

<br>

## 메모리 매핑 입출력
```
메모리의 일정공간을 입출력에 할당하는 기법을 메모리 매핑 입출력이라고 한다.
```
- 직접 메모리 접근은 인터럽트 방식에서 필수이지만, 사용하면 메모리가 복잡해진다.
   + 메모리에는 CPU가 사용하는 데이터와 입출력 장치가 사용하는 데이터가 섞여있기 때문
- 직접 메모리 접근을 통해 들어온 데이터를 메모리에 마구잡이로 두면 CPU가 사용하는 데이터와 섞여서 관리하기 어려워짐 => 이를 막기위해 메모리를 나누어 사용하는 방법이 도입
   + CPU가 사용하는 메모리 공간 / 직접 메모리 접근을 통해 들어오거나 나가는 데이터 공간을 분리

<br>

## 사이클 훔치기
```
직접 메모리 접근을 통해 입출력장치도 메모리를 사용할 수 있게 되었다.
그런데 CPU와 직접 메모리 접근이 동시에 메모리에 접근하려 한다면 어떻게 될까?
```
- 위 상황에서 보통은 CPU가 메모리 사용 권한을 양보한다.
  + 입출력장치의 속도가 CPU의 작업 속도보다 현저히 느리기 때문
  + 이러한 상황을 사이클 훔치기(Cycle Stealing)이라고 한다.